{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 框架的使用和示例：线性回归数据\n",
    "\n",
    "此笔记本是一个线性回归问题的例子，用来帮助用户理解和掌握如何使用训练器框架。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset \n",
    "from src.core.trainer import Trainer\n",
    "from src.core.plugin import EpochSavePlugin, LossLoggerPlugin, LoadTrainerStatePlugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 训练器实例\n",
    "\n",
    "训练器 `core.trainer.Trainer` 实例化时，需指定以下参数：\n",
    "- exp_name: 实验名称\n",
    "- epoch: 本次训练轮数\n",
    "- batch_size: 批数据数量\n",
    "- gradient_accumulation_step(=1): 梯度累积步数\n",
    "- init_random_seed(=None): 初始随机种子\n",
    "- device(=\"cpu\"): 训练设备\n",
    "- enable_auto_mixed_precision(=True): 自动混合精度\n",
    "- log_tool(=\"tensorboard\"): 日志工具\n",
    "- log_dir(=None): 日志目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    exp_name=\"lin-reg\",\n",
    "    epoch=20,\n",
    "    batch_size=40,\n",
    "    # gradient_accumulation_step=1,\n",
    "    \n",
    "    init_random_seed=0,\n",
    "    device=\"cuda:2\",\n",
    "    # enable_auto_mixed_precision=True,\n",
    "    \n",
    "    log_tool=\"tensorboard\",\n",
    "    # log_dir=\"tb-logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据集\n",
    "\n",
    "数据集为通用的 torch.utils.data.Dataset 类，但在使用本训练框架时，必须为数据集类实现 `__len__` 方法，否则模型将无法定义可复现的数据加载器。\n",
    "\n",
    "在本例子中，我们定义如下的线性数据集 `LinearData`，其数据保存在 `data.pt` 文件中，为随机生成的正太随机数所给出的线性模型（截距为 0）:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearData(Dataset):\n",
    "    def __init__(self, split=\"train\") -> None:\n",
    "        super().__init__()\n",
    "        data = torch.load(\"data.pt\")[split]\n",
    "        self.x = data[\"x\"]\n",
    "        self.y = data[\"y\"]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "dataset = LinearData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 神经网络模型（torch.nn.Module）\n",
    "\n",
    "神经网络模型为通用的 `torch.nn.Module` 类。\n",
    "\n",
    "在本例子中，我们使用一个简单的线性层:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = nn.Linear(10, 1, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 损失函数计算\n",
    "\n",
    "损失函数通过元组的形式传入训练器的`train`函数，其打包格式为：\n",
    "\n",
    "- ([name, ...], [loss_fn, ...])\n",
    "\n",
    "或\n",
    "\n",
    "- ([name, ...], [loss_fn, ...], [loss_weight, ...])\n",
    "\n",
    "在使用第一种打包格式时，各 loss 的计算权重默认为 1.0，损失函数的名称、计算函数、计算权重为一一对应关系。其中，`loss_fn` 接收的输入同一为两个位置参数：network 和 batch，分别对应神经网络和批数据。\n",
    "\n",
    "在本例子中，我们使用 MSE 作为损失函数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = nn.MSELoss()\n",
    "\n",
    "def mse_loss_fn(network, batch):\n",
    "    x, y = batch \n",
    "    y_hat = network(x).squeeze()\n",
    "    return mse(y, y_hat)\n",
    "\n",
    "losses = (\n",
    "    [\"mse\"],\n",
    "    [mse_loss_fn]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 优化器部署函数（Optional）\n",
    "\n",
    "在每次训练中，训练器将部署一个新的优化器实例，实例化优化器由 `optim_fn` 这一参数实现。`optim_fn` 参数为一个函数，它接收一个神经网络 `network` 作为唯一输入，并返回一个优化器实例。在框架中，默认的 `optim_fn` 会返回一个默认的 `AdamW` 优化器。\n",
    "\n",
    "在本例子中，我们新定义一个优化器部署函数，它将在训练中使用 SGD 优化器，并使用 0.02 的学习率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD \n",
    "\n",
    "def sgd_optim_fn(network):\n",
    "    return SGD(network.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 通过插件配置训练器功能\n",
    "\n",
    "使用 `core.plugin` 中的插件，为训练器添加功能:\n",
    "\n",
    "- 保存断点：使用 `EpochSavePlugin` 在每 5 个 epoch 之后保存一次训练断点\n",
    "- 记录损失值：使用 `LossLoggerPlugin` 在每 1 个 step 之后记录一次损失函数值（初始化时仅指定记录工具的种类和文件地址，此插件侧重于对损失值的记录）\n",
    "\n",
    "调用 `train` 方法开启训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.extend_plugins([\n",
    "    EpochSavePlugin(period=5),\n",
    "    LossLoggerPlugin(period=1)\n",
    "])\n",
    "\n",
    "trainer.train(\n",
    "    dataset=dataset,\n",
    "    network=network,\n",
    "    losses=losses,\n",
    "    optim_fn=sgd_optim_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 从断点恢复训练\n",
    "\n",
    "从训练断点恢复时，需要为训练器添加 `LoadTrainerStatePlugin` 插件（加载预训练权重而非随机初始化权重时，也使用此插件）：从训练断点恢复时，传入断点目录作为参数 checkpoint_path；加载模型权重时，传入权重文件作为参数 network_file\n",
    "\n",
    "在本例子中，我们新实例化一个配置相同的训练器 trainer_continue，从刚刚保存的训练断点 epoch-20 恢复训练。同时，设置 plugin_debug 参数为 True，训练过程中各插件的执行信息将被打印。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer_continue = Trainer(\n",
    "    exp_name=\"lin-reg-cont.\",\n",
    "    epoch=20,\n",
    "    batch_size=40,\n",
    "    device=\"cuda:2\",\n",
    "    plugin_debug=True\n",
    ").extend_plugins([\n",
    "    LoadTrainerStatePlugin(checkpoint_path=\"outputs/checkpoints/lin-reg/epoch-20\"),\n",
    "    EpochSavePlugin(5),\n",
    "    LossLoggerPlugin(1)\n",
    "])\n",
    "\n",
    "trainer_continue.train(\n",
    "    dataset=dataset,\n",
    "    network=network,\n",
    "    losses=losses,\n",
    "    optim_fn=sgd_optim_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 查看结果\n",
    "\n",
    "如果使用了 TensorBoard 记录训练过程，可以使用下面的单元格在笔记本中查看训练曲线等内容。或在命令行中使用类似的 tensorboard 启动命令查看，日志文件目录则在训练打印信息的最后一行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=tb-logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
